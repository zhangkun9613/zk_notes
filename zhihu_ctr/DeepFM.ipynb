{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "#define graph\n",
    "with graph.as_default():\n",
    "    '''\n",
    "    define variables\n",
    "    '''\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "#excute op\n",
    "with sess.as_default():\n",
    "    re = sess.run([op])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../train.npz')\n",
    "x_i = data['xi']\n",
    "x_v = data['xv']\n",
    "y = data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'feature_size' : 4260,\n",
    "    'field_size': 24,\n",
    "    'deep_size'  : [32,32],\n",
    "    'embedding_size' : 8,\n",
    "    'lr' : 0.01,\n",
    "    'l2_reg':0.01,\n",
    "    'deep_init': None,\n",
    "    'deep_regularizer' : None,\n",
    "    'deep_activation' : None,\n",
    "    'epochs':1,\n",
    "    'batch_size':32,\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sys\n",
    "class DeepFM(BaseEstimator,TransformerMixin):\n",
    "    \n",
    "    def __init__(self,feature_size,field_size,embedding_size,deep_size,lr,l2_reg,epochs,batch_size,\n",
    "                deep_init,deep_regularizer,deep_activation,):\n",
    "        self.feature_size = feature_size\n",
    "        self.field_size = field_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.deep_size = deep_size\n",
    "        self.lr = lr\n",
    "        self.l2_reg = l2_reg\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.deep_init = tf.initializers.glorot_normal()\n",
    "        self.deep_regularizer = tf.contrib.layers.l2_regularizer(scale=self.l2_reg)\n",
    "        self.deep_activation = tf.nn.relu\n",
    "        self.eval_metric = roc_auc_score\n",
    "        self.init_graph()\n",
    "                 \n",
    "        \n",
    "    \n",
    "    def dense_layer(self,inputs,units,bias_init=tf.initializers.constant(0.01) ,activation=tf.nn.relu, name=\"\"):\n",
    "        # bias 初始化为0.01,保持relu激活\n",
    "        return tf.layers.dense(inputs = inputs,units = units, kernel_initializer=self.deep_init, use_bias=True,\n",
    "                               kernel_regularizer=self.deep_regularizer, bias_initializer=bias_init,activation=activation,name=name)\n",
    "    def init_graph(self):\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.feat_index = tf.placeholder(tf.int32,shape=[None,self.field_size],name='feat_index')\n",
    "            self.feat_value = tf.placeholder(tf.float32,shape=[None,self.field_size], name = 'feat_value')\n",
    "            self.labels = tf.placeholder(tf.float32,shape=[None,1],name = 'labels')\n",
    "            self.train_phase = tf.placeholder(tf.bool,name = 'train_phase')\n",
    "                 \n",
    "                 \n",
    "            #input\n",
    "            self.weights = {};\n",
    "            self.weights['feature_embedding'] = tf.Variable(tf.random_normal(shape=[self.feature_size,self.embedding_size],mean=0.0,stddev=0.01,name='feature_embedding'))\n",
    "             # weights of first_order\n",
    "            self.weights['feature_bias'] = tf.Variable(tf.random_normal(shape=[self.feature_size,1],mean=0.0,stddev=1.0,name='feature_bias'))\n",
    "            \n",
    "            self.feature_embedding = tf.nn.embedding_lookup(self.weights['feature_embedding'],ids = self.feat_index) # batch_size * field_size * embedding_size\n",
    "            \n",
    "            \n",
    "           \n",
    "            #fm part \n",
    "            # first order\n",
    "            feat_value = tf.reshape(self.feat_value, shape=[-1,self.field_size,1]) #batch_size * field_size * 1\n",
    "            self.first_order = tf.nn.embedding_lookup(self.weights['feature_bias'],self.feat_index) # batch_size * filed_size * 1\n",
    "            self.first_order = tf.reduce_sum(tf.multiply(self.first_order,feat_value),axis=2) # batch_size * filed_size (squeeze)\n",
    "            \n",
    "            #second_order\n",
    "            self.embeddings = tf.multiply(self.feature_embedding,feat_value) # batch_size * field_size * embedding_size\n",
    "                 \n",
    "            self.square_sum_embed = tf.square(tf.reduce_sum(self.embeddings,axis=1)) # batch_size * embedding_size\n",
    "            \n",
    "            self.sum_square_embed = tf.reduce_sum(tf.square(self.embeddings),axis=1) # batch_size * embedding_size\n",
    "            \n",
    "            self.second_order = 0.5 * tf.subtract(self.sum_square_embed,self.square_sum_embed)\n",
    "            \n",
    "            self.fm_output = tf.concat([self.first_order,self.second_order],axis = 1)\n",
    "        \n",
    "            #deep part\n",
    "            self.deep_input = tf.reshape(self.embeddings,shape=[-1,self.field_size*self.embedding_size])\n",
    "            self.deep_layer_nums = len(self.deep_size)\n",
    "            self.deep_layers = {}\n",
    "            self.deep_layers['layer_0'] = self.deep_input\n",
    "            for i in range(self.deep_layer_nums):\n",
    "                self.deep_layers['layer_{}'.format(i+1)] = self.dense_layer(self.deep_layers['layer_{}'.format(i)],self.deep_size[i],name='layer_{}'.format(i))\n",
    "            self.deep_output = self.deep_layers['layer_{}'.format(self.deep_layer_nums-1)]\n",
    "            \n",
    "            # loss and optimitizer\n",
    "            self.feature_out = tf.concat([self.deep_output,self.fm_output], axis = 1)\n",
    "            self.out = self.dense_layer(self.feature_out,1,activation=tf.nn.sigmoid,name=\"output\")\n",
    "           \n",
    "            self.loss = tf.losses.log_loss(predictions=self.out,labels=self.labels)\n",
    "            self.print = tf.print(\"loss:\",self.out,output_stream=sys.stdout)\n",
    "            if self.l2_reg > 0 :\n",
    "                 self.loss += tf.losses.get_regularization_loss()\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr).minimize(self.loss)\n",
    "            \n",
    "            #init\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.sess = tf.Session()\n",
    "            init = tf.global_variables_initializer()\n",
    "            self.sess.run(init)\n",
    "    \n",
    "    def fit_on_batch(self,x_i,x_v,labels):\n",
    "        feed_dict = {\n",
    "            self.feat_index:x_i,\n",
    "            self.feat_value:x_v,\n",
    "            self.labels:labels\n",
    "        }\n",
    "        loss, _,out= self.sess.run([self.loss,self.optimizer,self.out],feed_dict = feed_dict)\n",
    "        print(out,loss)\n",
    "        return loss\n",
    "    \n",
    "    def shuffle_data(self,X_i,X_v,Y):\n",
    "        now_state = np.random.get_state()\n",
    "        np.random.shuffle(X_i)\n",
    "        np.random.set_state(now_state)\n",
    "        np.random.shuffle(X_v)\n",
    "        np.random.set_state(now_state)\n",
    "        np.random.shuffle(Y)\n",
    "        \n",
    "    def get_batch(self,X_i,X_v,Y,batch_size,step):\n",
    "        pos_s = step * batch_size\n",
    "        pos_e = (step+1) * batch_size\n",
    "        # numpy slice 越界会自动选择到最后一个\n",
    "        return X_i[pos_s:pos_e],X_v[pos_s:pos_e],Y[pos_s:pos_e]\n",
    "    \n",
    "    def evalute(self, x_v,x_i,y_label):\n",
    "        y_pred = self.predict(x_i,x_v)\n",
    "        return self.eval_metric(y_label,y_pred)\n",
    "    \n",
    "    def predict(self,x_v,x_i):\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self,X_i,X_v,Y,\n",
    "           Xi_valid=None,Xv_valid=None,Y_valid=None):\n",
    "        X_i = X_i.copy(); X_v=X_v.copy(); Y = Y.copy()\n",
    "        for epoch in range(self.epochs):\n",
    "            batch_nums = np.ceil(X_i.shape[0]/self.batch_size).astype(np.int64)\n",
    "            if shuffle:\n",
    "                self.shuffle_data(X_i,X_v,Y)\n",
    "            total_loss = 0\n",
    "            for step in range(batch_nums):\n",
    "                x_i,x_v,y = self.get_batch(X_i,X_v,Y,self.batch_size,step)\n",
    "                loss = self.fit_on_batch(x_i,x_v,y)\n",
    "                total_loss += loss\n",
    "                if(step % 100 == 0):\n",
    "                    tf.logging.info(\"step={},loss={}\".format(step,total_loss/(100*self.batch_size)))\n",
    "                    total_loss = 0\n",
    "                \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6993106 ]\n",
      " [0.64715344]\n",
      " [0.6556818 ]\n",
      " [0.68481594]\n",
      " [0.7975112 ]\n",
      " [0.76910645]\n",
      " [0.5599257 ]\n",
      " [0.68055105]\n",
      " [0.7085018 ]\n",
      " [0.56484705]] 1.4833128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4833128"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmmodel = DeepFM(**config) \n",
    "fmmodel.fit_on_batch(x_i[0:10],x_v[0:10],y[0:10].reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489162,)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489162, 24)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#params: 45637\n"
     ]
    }
   ],
   "source": [
    "reload(deepfm)\n",
    "model = deepfm.DeepFM(4260,24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6118095"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_on_batch(x_i[0:10],x_v[0:10],y[0:10].reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmmodel.fit(x_i[0:10000],x_v[0:10000],y[0:10000].reshape([-1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9489162, 24)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Inserts a placeholder for a tensor that will be always fed.\n",
       "\n",
       "**Important**: This tensor will produce an error if evaluated. Its value must\n",
       "be fed using the `feed_dict` optional argument to `Session.run()`,\n",
       "`Tensor.eval()`, or `Operation.run()`.\n",
       "\n",
       "For example:\n",
       "\n",
       "```python\n",
       "x = tf.placeholder(tf.float32, shape=(1024, 1024))\n",
       "y = tf.matmul(x, x)\n",
       "\n",
       "with tf.Session() as sess:\n",
       "  print(sess.run(y))  # ERROR: will fail because x was not fed.\n",
       "\n",
       "  rand_array = np.random.rand(1024, 1024)\n",
       "  print(sess.run(y, feed_dict={x: rand_array}))  # Will succeed.\n",
       "```\n",
       "\n",
       "@compatibility(eager)\n",
       "Placeholders are not compatible with eager execution.\n",
       "@end_compatibility\n",
       "\n",
       "Args:\n",
       "  dtype: The type of elements in the tensor to be fed.\n",
       "  shape: The shape of the tensor to be fed (optional). If the shape is not\n",
       "    specified, you can feed a tensor of any shape.\n",
       "  name: A name for the operation (optional).\n",
       "\n",
       "Returns:\n",
       "  A `Tensor` that may be used as a handle for feeding a value, but not\n",
       "  evaluated directly.\n",
       "\n",
       "Raises:\n",
       "  RuntimeError: if eager execution is enabled\n",
       "\u001b[0;31mFile:\u001b[0m      ~/miniconda2/envs/ydzhang/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.placeholder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
